.so syktsu.tmac
.
.char \[one] \s-2\v'-0.3m'1\v'+0.3m'\s+2
.
.
.TC
.
.
.H1 "Введение"
.PP
Данная работа посвящена задаче распознавания номеров.  Суть этой задачи состоит
в следующем: имеется изображение \*- требуется найти на нем пластину с
автомобильным номером и вывести символы, находящиеся на ней, в виде текста.
.PP
Несмотря на то, что компьютерные программы, решающие данную задачу уже
существуют, некоторые проблемы по-прежнему имеются. Главная из них состоит в
том, что качественных материалов, посвященных решению этой проблемы крайне
мало. В большинстве статей авторы либо используют OpenCV (фреймворк, содержащий
готовые реализации алгоритмов, необходимых для решения), либо утаивают важные
детали реализации, без которых проблему решить невозможно, либо просто
демонстрируют полное непонимание используемых ими методов.
.PP
Первая цель этой работы \*- написать программу, способную распознавать
автомобильные номера, не используя каких-либо сторонних библиотек, кроме
стандартных библиотек языка Си и библиотеки для открытия разных форматов
изображений. Вторая цель \*- это попытаться описать используемые методы
доступным языком, так как, как уже было сказано выше, при их описании часто
упускаются из виду важные детали.
.PP
Задача распознавания автомобильных номеров состоит из нескольких этапов: первый
\*- это нахождение пластины с номером на изображении, второй \*- приведение его
к стандартному виду (исправление перспективных искажений, выравнивание
освещения, и т. д.), а третий \*- распознавание символов, находящихся на
пластине.
.PP
Для решения задачи было выбрано машинное обучение. Метод, с помощью которого,
имея большое число эмпирических данных об исследуемой проблеме (в случае с
автомобильными номерами \*- это фотографии, на которых пластины с номером
находятся в естественных для них условях), можно найти способ её решения.
.PP
В первом разделе описывается, что такое машинное обучение, а также дается
значение терминов, используемых в этой работе. Остальные разделы описывают
применяемые методы, их реализацию, а также результаты их работы.
.
.
.H1 "Необходимая терминология"
.
.H2 "Машинное обучение"
.PP
Машинное обучение \*- это выявление каких-либо закономерностей по набору
эмпирических данных. Т.е. имеется какое-либо явление или объект, а также
множество данных, полученных непосредственно с него (это множество называют
\*Iобучающей выборкой\*P), требуется на основе этого множества выявить
взаимосвязи, присутствующие в данном объекте или явлении.
.PP
Машинное обучение можно разделить на \*Iобучение с учителем\*P и \*Iобучение
без учителя\*P. В первом случае к каждому примеру из обучающей выборки
прилагается ответ, который должна дать обучаемая система, исследуя его, а во
втором \*- системе дается только обучающая выборка.
.PP
Распространенным примером обучения с учителем является задача классификации, о
которой пойдет речь в следующем разделе. А как пример обучения без учителя,
можно привести задачу \*Iобнаружения выбросов\*P: поиск в обучающей выборке
небольшого числа значений, сильно отличащихся от остальных.
.
.H2 "Классификация"
.PP
Классификация \*- это задача, суть которой состоит в следующем: имеется
множество объектов (обучающая выборка), разделенное на определенные группы
(классы), по какому-либо признаку, требуется найти способ, которым можно
определить принадлежность к одному из этих классов для произвольного объекта
(классифицировать объект) того же типа, что и объекты из обучающей выборки.
По сути, задача классификации является разновидностью машинного обучения.
.PP
Как пример можно привести распознавание текста, где в качестве классов
выступают буквы, цифры, знаки препинания и все остальное (отдельный класс), а
изображения с ними \*- в качестве обучающей выборки. Тогда, чтобы
классифицировать изображение, надо определить, изображены ли на ней буква,
цифра или знак препинания, если да, то какие.
.PP
Еще одним интересным примером является проверка на наличие определенного
объекта на изображении, например, лица. В этом случае класса всего два:
изображение лица, изображение не лица. Тогда обучающая выборка будет состоять
из разных изображений, где на одних лица есть, а на других \*- нет.
Классификация изображения будет состоять в том, чтобы определить, изображено
ли на нем лицо.
.
.
.H1 "Каскад Хаара"
.PP
Каскад Хаара \*- способ обнаружения объектов на изображении, основанный на
машинном обучении, идея которого была была предложена в статье за авторством
\*IПола Виолы (Paul Viola)\*P и \*IМайкла Джонса (Michael Jones)\*P.
.PP
Обученный каскад Хаара, принимая на вход изображение, определяет, есть ли на
нем искомый объект, т.е. выполняет задачу классификации, разделяя входные
данные на два класса (есть искомый объект, нет искомого объекта). 
.PP
Правильно обученный каскад Хаара имеет хорошую скорость выполнения
классификации, а также неплохую устойчивость к разного рода отклонениям.
Изначально данный способ был предназначен для обнаружения лиц, однако его
можно использовать и для обнаружения других объектов, например, пластины с
автомобильным номером.
.
.H2 "Признаки Хаара"
.PP
Признак Хаара является набором прямоугольных областей изображения, примыкающих
друг к другу и разделенных на две группы. Возможных признаков Хаара огромное
множество (разнообразные комбинации областей разной ширины и высоты с разными
позициями на изображении). Первоначальный набор признаков зависит от реализации
и конкретной задачи (в разделе, посвященном алгоритму \*IAdaBoost\*P, описано,
как из этого набора выбираются требуемые признаки). 
.sp 1.0v
.PSPIC haar_primitives.eps 16m
.ps -2
.vs -2
.ce 100
Рис. 1. Комбинации прямоугольных областей, которые использовались при
написании этой статьи.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
Чтобы вычислить значение конкретного признака Хаара для какого-либо
изображения, надо сложить яркости пикселей изображения в первой и второй группах
прямоугольных областей по отдельности, а затем вычесть из первой полученной
суммы вторую. Полученная разность и есть значение конкретного признака Хаара
для данного изображения.
.sp 1.0v
.PSPIC numprim.eps 16m
.ps -2
.vs -2
.ce 100
Рис. 2. Признак Хаара на изображении.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
Рис. 2 изображает пример признака Хаара на изображении: белые прямоугольники
\*- первая группа группа областей, а черный \*- вторая. Значение признака Хаара
\*- это разность сумм яркостей пикселей первой и второй группы. В
математической форме это будет выглядеть так:
.sp 1v
.EQ
a sub i = sum from {i={y sub a sub i}} to {{y sub a sub i}+{h sub a sub i}-1}
~~
sum from {j^=^{x sub a sub i}} to {{x sub a sub i}+{w sub a sub i}-1} x sub {i j}
~~~~~~~~
b sub i = sum from {i={y sub b sub i}} to {{y sub b sub i}+{h sub b sub i}-1}
~~
sum from {j^=^{x sub b sub i}} to {{x sub b sub i}+{w sub b sub i}-1} x sub {i j}
~~~~~~~~
.EN
.sp 1.0v
.EQ
h = sum from {i ^ = ^ 1} to {{N sub a}} {a sub i}
- sum from {i ^ = ^ 1} to {{N sub b}} {b sub i}
~,
.EN
.sp 1.0v
где $x sub ij$ \*- яркость пискеля с координатами $[i, j]$, $a sub i$ \*- сумма
яркостей пикселей в $i$-й области первой группы, $b sub i$ \*- сумма яркостей
пикселей в $i$-й области второй группы, $h$ \*- значение признака Хаара для
этого изображения, $h sub a sub i$ \*- высота $i$-й области первой группы,
$w sub a sub i$ \*- ширина $i$-й области первой группы, $h sub b sub i$ \*-
высота $i$-й области второй группы, $w sub b sub i$ \*- ширина $i$-й области
второй группы, $N sub a$ \*- количество областей первой группы, $N sub b$ \*-
количество областей второй группы, а $h$ \*- значение признака Хаара для этого
изображения.
.
.H2 "Нормализация изображения"
.PP
Прежде чем классифицировать изображение или использовать его как пример для
обучения, это изображение следует нормализовать, т. е. привести к стандартному
виду. При использовании каскадов Хаара это означает, что надо перевести
изображение из текущей цветовой схемы в черно-белую, а также нормализовать
(сделать равным единице) его среднеквадратичное отклонение.
.PP
Следует начать с перевода изображения в черно-белую цветовую схему. Так как
обычно изображения изначально загружаются в цветовой схеме \*IRGB\*P, будет
приведена формула только для нее:
.sp 1.0
.EQ
i [ x; y ] = size -2 {{{I sub r} [ x; y ] + {I sub g} [ x; y ] + {I sub b}
[ x; y ]} over 3}
~ ,
.EN
.sp 1.0
где $i [ x; y ]$ \*- пиксель черно-белого изображения, а $I sub r [x; y]$,
$I sub g [x; y]$ и $I sub b [x; y]$ \*- соотвественно красная, синяя или
зеленая компоненты изображения.
.PP
После этого надо нормализовать среднеквадратическое отклонение. Это необходимо
для того, чтобы разница в освещенности на фотографиях оказывала минимум влияния
на результат классификации. Для этого следует вычислить среднее арифметическое
изображения по следующей формуле:
.sp 1.0
.EQ
a = {size -2 {1 over wh}} {sum from {i ^ = ^ 1} to w}
{sum from {j ^ = ^ 1} to h} {x sub ij}
~ ,
.EN
.sp 1.0
а потом найти среднеквадратическое отклонение по формуле:
.sp 1.0
.EQ
sigma = left ( {{size -2 {1 over hw}} {sum from {i ^ = ^ 1} to h}
{sum from {j ^ = ^ 1} to w} { ({x sub ij} - a) sup 2 }} right )
sup {~ {1 over 2}}
.EN
.sp 1.0
.PP
После того, как среднеквадратическое отклонение было найдено, можно его
нормализовать, поделив на него значение каждого пикселя в черно-белом
изображении:
.sp 1.0
.EQ
{x sub ij} = {size -2 {{x sub ji} over sigma}}
.EN
.sp 1.0
.PP
Теперь полученное изображение можно использовать для обучения каскада Хаара.
Также эти операции следует выполнять с изображением перед его классификацией.
.
.H2 "Интегральная форма представления изображения"
.PP
Вычисление значения каждого признака Хаара для изображения требует много
операций сложения. Однако, если использовать интегральную форму изображения,
количество вычислений можно сильно уменьшить.
.PP
В интегральной форме изображения значение каждого пикселя является суммой
яркостей этого пикселя и всех пикселей, что находятся выше и левее
него (если пиксель с координатами $[1; 1]$ находится в верхнем левом углу
изображения):
.sp 1v
.EQ
S sub {yx} = sum from {i^=^1} to {y} sum from {j^=^1} to {x} {x sub ij}
~,
.EN
.sp 1.0v
где $S sub yx$ \*- значение пикселя интегральной формы изображения с
координатами $[y; x]$, а $x sub ij$ \*- значение пикселя исходного изображения
с координатами $[i; j]$.
.PP
Переведя изображение в интегральную форму, можно вычислять значения признаков
Хаара для него, не выполняя суммирование всех требуемых значений яркостей
каждый раз по новой. Достаточно посчитать сумму яркостей для каждой
прямоугольной области, используя свойства интегральной формы изображения:
.sp 1.0v
.EQ
left { lpile {
a sub i
= S[{{y sub a sub i} + h sub a sub i};{{x sub a sub i} + w sub a sub i}]
above
a sub i
= S[{{y sub a sub i} + h sub a sub i};{{x sub a sub i} + w sub a sub i}]
- S[{{y sub a sub i} + h sub a sub i};{x sub a sub i}]
above a sub i
= S[{{y sub a sub i} + h sub a sub i};{{x sub a sub i} + w sub a sub i}]
- S[{y sub a sub i};{{x sub a sub i} + w sub a sub i}]
above a sub i
= S[{{y sub a sub i} + h sub a sub i};{{x sub a sub i} + w sub a sub i}]
- S[{y sub a sub i};{{x sub a sub i} + w sub a sub i}]
- S[{{y sub a sub i} + h sub a sub i};{x sub a sub i}]
+ S[{y sub a sub i};{x sub a sub i}]
}
lpile {
, y = 1, x = 1
above
, y > 1, x = 1
above
, y = 1, x > 1
above
, y > 1, x > 1
} right ""
.EN
.sp 1.0v
.EQ
left { lpile {
b sub i
= S[{{y sub b sub i} + h sub b sub i};{{x sub b sub i} + w sub b sub i}]
above
b sub i
= S[{{y sub b sub i} + h sub b sub i};{{x sub b sub i} + w sub b sub i}]
- S[{{y sub b sub i} + h sub b sub i};{x sub b sub i}]
above b sub i
= S[{{y sub b sub i} + h sub b sub i};{{x sub b sub i} + w sub b sub i}]
- S[{y sub b sub i};{{x sub b sub i} + w sub b sub i}]
above b sub i
= S[{{y sub b sub i} + h sub b sub i};{{x sub b sub i} + w sub b sub i}]
- S[{y sub b sub i};{{x sub b sub i} + w sub b sub i}]
- S[{{y sub b sub i} + h sub b sub i};{x sub b sub i}]
+ S[{y sub b sub i};{x sub b sub i}]
}
lpile {
, y = 1, x = 1
above
, y > 1, x = 1
above
, y = 1, x > 1
above
, y > 1, x > 1
} right ""
.EN
.sp 1.0v
где $S[y;x]$ \*- значение пикселя интегральной формы изображения. Далее можно
вычислить значение признака Хаара как обычно:
.sp 1.0v
.EQ
h = sum from {i^=^1} to {{N sub a}} {a sub i}
- sum from {i^=^1} to {{N sub b}} {b sub i}
~,
.EN
.sp 1.0v
.PSPIC imgintegral.eps 16m
.ps -2
.vs -2
.ce 100
Рис. 3. Вычисление с помощью интегральной формы изображения.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
Рис. 3 иллюстрирует, что для того, чтобы вычислить сумму значений пикселей в
прямоугольнике $D$, можно использовать интегральную форму изображения: в ней
точка $a$ будет являться суммой значений пикселей в прямоугольнике $A$, точка
$b$ \*- суммой значений пикселей в прямоугольниках $A$ и $B$, точка $c$ \*-
суммой значений пикселей в прямоугольниках $A$ и $C$, а точка $d$ \*- суммой
значений пикселей в прямоугольниках $A$, $B$, $C$ и $D$. Тогда сумма значений
пикселей в прямоугольнике $D$ будет равна $d$ - $c$ - $b$ + $a$.
.
.H2 "Алгоритм AdaBoost"
.PP
Для выбора признаков, лучше всего классифицирующих изображения используется
алгоритм \*IAdaBoost\*P (adaptive boosting). Этот алгоритм построен на идее,
что из большого числа простых способов классификации (называемых \*Iслабыми
классификаторами\*P) можно составить новый способ, выполняющий эту задачу
намного эффективнее.
.PP
В данном случае слабый классификатор \*- это функция, которая принимает на вход
изображение, вычисляет значение соответствующего ей признака Хаара для этого
изображения и сравнивет это значение с порогом, возвращая либо $0$, либо $1$.
.sp 1.0v
.EQ
{h sub i}(x) = left {
lpile {
1, {p sub i}{f sub i}(x) < {p sub i}{theta sub i}
above 0, иначе
}
right ""
~,
.EN
.sp 1.0v
где $theta sub i$ \*- порог, $x$ \*- входное изображение, ${f sub i}(x)$ \*-
значение соотвествующего признака Хаара для изображения $x$, $p sub i$ \*-
направление знака неравенства\[one], а ${h sub i}(x)$ \*- слабый классификатор.
.
.FS \[one]
Принимает одно из двух значений: $1$ или $-1$. Если оно равно $1$, ничего не
меняется, если же оно равно $-1$, знак неравенства начинает работать в обратную
сторону. Такая запись используется из-за своей краткости, а так же потому,
что при реализации на некоторых архитектурах операция умножения работает
намного быстрее, чем условные операторы.
.FE
.
.PP
Данный алгоритм перебирает все возможные слабые классификаторы и выбирает те,
которые допускают меньше всего ошибок. Важная особенность алгоритма в том, что
каждому изображению из обучающей выборки соответсвует определенный вес, и после
выбора очередного слабого классификатора веса перераспределяется так, что
неверно классифицированные изображения начинают сильнее влиять на значение
ошибки.
Ниже приведен полный алгоритм:
.sp 0.5v
.RS
Входные данные:
.RS
.PI
$h sub i$ \*- $i$-й признак Хаара (из всех возможных).
.PI
$E sub i$ \*- $i$-й обучающий пример.
.PI
$y sub i$ \*- $0$, если $i$-й обучающий пример отрицательный, и $1$, если $i$-й
обучающий пример положительный.
.PI
$n$ \*- количество обучающих примеров.
.RE
.sp 1.0v
Переменные:
.RS
.PI
$w sub i$ \*- вес, соответствующий $i$-му обучающему примеру.
.PI
$theta sub i$ \*- порог для $i$-го признака Хаара, дающий наименьшую ошибку.
.PI
$p sub i$ \*- направление знака неравенства для $i$-го признака
Хаара, дающее наименьшую ошибку.
.PI
$epsilon sub i$ \*- ошибка $i$-го слабого классификатора.
.PI
${h dot} sub i$ \*- слабый классификатор, выбранный на $i$-й итерации.
.PI
$epsilon dot$ \*- минимальное значение ошибки слабого классификатора на текущей
итерации.
.PI
$beta sub i$ \*- минимальное значение ошибки слабого классификатора на $i$-й
итерации, представленное в другой форме (для оптимизации вычислений и экономии
места на бумаге).
.RE
.sp 1.0v
.PI 1.
Инициализировать веса обучающих примеров:
.sp 1.0v
.EQ
left {
lpile {
w sub i = size -2 {1 over 2m}, если~y sub i = 0
above w sub i = size -2 {1 over 2l}, если~y sub i = 1
}
right ""
~,
.EN
.sp 1.0v
где $m$ \*- число отрицательных примеров, а $l$ \*- число положительных
примеров.
.sp 1.0v
.PI 2.
Для $t = 1, .., T$:
.RS
.PI a.
Нормализовать веса обучающих примеров:
.sp 1.0v
.EQ
w sub i = size -2 {{w sub i} over {sum from {j^=^1} to n {w sub j}}}
.EN
.sp 1.0v
.PI b.
Найти для каждого признака Хаара, порог и направление знака 
неравенства такие, чтобы слабый классификатор, составленный из них дал
наименьшую ошибку:
.sp 1.0v
.EQ
{h dot}^(x) = left {
lpile {
1, {p sub j}{h sub j}(x) < {p sub j}{theta sub j}
above 0, иначе
}
right ""
~,
~~~~
epsilon sub j = sum from k to n {{w sub k}|{h dot}^({E sub k}) - {y sub k}}|
~ \*- ~ минимальный 
~~
.EN
.sp 1.0v
.PI c.
Hайти классификатор с наименьшей ошибкой:
.sp 1.0v
.EQ
{epsilon dot} = min {epsilon sub j}
.EN
.sp 1.0v
.EQ
{{h dot} sub t} = left {
lpile {
1, {p sub n}{h sub n}(x) < {p sub n}{theta sub n}
above 0, иначе
}
right ""
~,
.EN
.sp 1.0v
где $n$ \*- номер слабого классификатора, дающего наименьшую ошибку.
.sp 1.0v
.PI d.
Обновить веса обучающих примеров:
.sp 1.0v
.EQ
beta sub t = size -2 {{{epsilon dot}} over {(1 - {epsilon dot})}}
.EN
.sp 1.0v
.EQ
w sub i = {w sub i} {beta sub t} sup {1^-^{|{{h dot} sub t}({E sub i})^-^{y sub i}}|}
.EN
.sp 1.0v
.RE
.PI 3.
Итоговый сильный классификатор:
.sp 1.0v
.EQ
H(x) = left { lpile {
1, ~ sum from {t = 1} to T {log ({size -2 {1 over {beta sub t}}}) {h dot} sub t}({E sub i})
>= size -2 {1 over 2} sum from {t = 1} to T {log ({size -2 {1 over {beta sub t}}})}
above
0, ~ roman "иначе"
}
right ""
.EN
.sp 1.0v
.RE
.sp 0.5v
.PP
Стоит отметить, что под "всеми возможными признаками Хаара" подразумеваются
признаки Хаара, имеющие заранее определенное взаимное расположение
прямоугольников, а также их версии, маштабированные по ширине и высоте так,
чтобы те не выходили за границы окна с заданными шириной и высотой. Все
обучающие примеры должны иметь такую же ширину и высоту, как и окно.
.PP
Полученный сильный классификатор уже способен выполнять задачу классификации,
хоть и очень медленно. Значение
${a sub i} = log {size -2 {1 over {beta sub i}}}$ далее будет рассматриваться
как "коэффициент $i$-го слабого классификатора".
.
.H2 "Быстрое вычисление наилучшего" "порога для слабого классификатора"
.PP
Перебор всех возможных признаков Хаара выполняется за приемлимое время. Однако
нахождение наилучшего порога и направления знака неравенства таким же способом
требует такого количества времени, что применение на практике каскадов Хаара
становится затруднительным (так как порог \*- число вещественое, количество его
возможных значений ограничено лишь особенностями представления вещественных
чисел на конкретной машине).
.PP
Однако, если обратить больше внимания на то, какую задачу должен выполнять
порог в слабом классификаторе, можно заметить, что перебирать все возможные
его значения нет нужды.
.PP
Если предположить, что веса всех обучающих примеров равны, то порог должен
разделять плохие и хорошие примеры по значению признака Хаара таким образом,
чтобы с одной стороны было как можно больше хороших, а с другой \*- как можно
больше плохих (с какой стороны должны быть какие примеры, определяет
направление знака неравенства). Но так как веса обычно разные, то задачу
надо изменить так: сумма весов примеров, находящихся не по ту сторону
порога, по которую им следует находиться, должна быть минимальной.
.PP
Так как значение признака Хаара для изображения
есть обычное вещественное число, то это можно изобразить так:
.sp 1.0v
.PSPIC primvals.eps 25m
.ps -2
.vs -2
.ce 100
Рис. 4
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
На рис. 4: по горизонтальной оси расположены номера обучающих примеров, по
вертикальной \*- значения признаков Хаара для соответствующих обучающих
примеров. Зеленые точки \*- значение признака Хаара для хороших примеров,
красные точки \*- для плохих. Горизонтальная линия на графике \*- один из
возможных порогов.
.PP
Отсортировав обучающие примеры по их значению признака Хаара, можно получить
такую картинку:
.sp 1.0v
.PSPIC primvalssorted.eps 25m
.ps -2
.vs -2
.ce 100
Рис. 5
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
На рис. 5 по горизонтальной оси расположены номера обучающих примеров, по
вертикальной \*- значения признаков Хаара для соответствующих обучающих
примеров. Зеленые точки \*- значение признака Хаара для хороших примеров,
красные точки \*- для плохих.
.PP
Теперь можно заметить, что все пороги, находящиеся между двумя соседними
точками на отсортированном графике, дают одинаковые результаты. Следовательно,
чтобы получить наименьшую возможную ошибку, достаточно проверить только $n - 1$
порогов, где $n$ \*- количество обучающих примеров, беря как значение порога,
например, среднее между двумя соседними отсортированными значениями признака
Хаара.
.PP
Однако, даже после этого, перебор признаков Хаара занимает очень много времени.
Одной из причин является вычисление ошибки слабого классификатора, требующее
большое количество операций суммирования и выполняющееся огромное количество
раз.
.PP
К счастью, есть способ вычислять ошибку слабого классификатора, не выполняя
столько операций суммирования. Для этого можно использовать трюк, очень похожий
на интегральную форму представления изображения:
.sp 1.0v
.RS
.PI
$h$ \*- признак Хаара, для которого ищется порог.
.PI
$E sub i$ \*- $i$-й обучающий пример.
.PI
$y sub i$ \*- $0$, если $i$-й обучающий пример отрицательный, и $1$, если $i$-й
обучающий пример положительный.
.PI
$n$ \*- количество обучающих примеров.
.PI
$w sub i$ \*- вес, соответствующий $i$-му обучающему примеру.
.PI
$w sup +$, $w sup -$ \*- дополнительные массивы.
.PI
$theta dot$ \*- порог проверяемый на текущей итерации.
.PI
$epsilon dot$ \*- ошибка на текущей итерации.
.PI
$epsilon$ \*- наименьшая полученная ошибка, изначально равна $1$.
.PI
$theta$ \*- значение порога, при котором была получена наименьшая ошибка.
.PI
$p$ \*- направление знака неравенства, при котором была получена наименьшая
ошибка.
.RE
.sp 1.0v
.RS
.PI 1.
Отсортировать обучающие примеры. Веса и элементы массива $y$ расположить в
таком же порядке, как и отсортированные примеры (т.е. чтобы каждому примеру
после сортировки соответствовал тот же вес и элемент из $y$, что и до
сортировки).
.PI 2.
Сделать два дополнительных массива, в первом массиве $i$-й элемент содержит
сумму весов хороших примеров до $i$-го значения, а во втором \*- плохих:
.sp 1.0v
.EQ
{w sup +} sub i = sum from {j = 1} to i {left { lpile{{w sub j},
~ roman "если" ~ {y sub j = 1} above 0, ~ roman "если" ~ {y sub j = 0} }}
.EN
.sp 1.0v
.EQ
{w sup -} sub i = sum from {j = 1} to i {left { lpile{{w sub j},
~ roman "если" ~ {y sub j = 0} above 0, ~ roman "если" ~ {y sub j = 1} }}
.EN
.sp 1.0v
.PI 3.
Для всех $i$ от $2$ до $n$:
.RS
.PI a.
Вычислить значение проверяемого порога:
.sp 1.0v
.EQ
{theta dot} = { size -2 { h ^ ( {E sub {i - 1}} ) + h ^ ( {E sub i} ) } } over 2
.EN
.sp 1.0v
.PI b. 
Посчитать ошибку для $p = 1$:
.sp 1.0v
.EQ
{epsilon dot} = {w sup -} sub {i - 1} ~ + ~ {w sup +} sub n
~ - ~ {w sup +} sub {i - 1}
.EN
.sp 1.0v
.PI c.
Если ошибка проверяемого порога меньше текущей минимальной ошибки, запомнить
этот порог, ошибку и направление знака неравенства:
.sp 1.0v
.EQ
roman "если" ~ { {epsilon dot} < epsilon },
roman "тогда" ~ { epsilon = {epsilon dot} }, { theta = {theta dot} }, {p = 1} 
.EN
.sp 1.0v
.PI d.
Посчитать ошибку для $p = - ^ 1$:
.sp 1.0v
.EQ
{epsilon dot} = {w sup +} sub {i - 1} ~ + ~ {w sup -} sub n
~ - ~ {w sup -} sub {i - 1}
.EN
.sp 1.0v
.PI e.
Если ошибка проверяемого порога меньше текущей минимальной ошибки, запомнить
этот порог, ошибку и направление знака неравенства:
.sp 1.0v
.EQ
roman "если" ~ { {epsilon dot} < epsilon },
roman "тогда" ~ { epsilon = {epsilon dot} }, { theta = {theta dot} }, {p = - ^ 1} 
.EN
.RE
.sp 1.0v
.RE
.sp 0.5v
.
.H2 "Каскад классификаторов"
.PP
Если уменьшать значение порога \*Iсильного\*P классификатора, уменьшается
количество ложных негативных срабатываний (неверно классифицированных хороших
примеров) и увеличивается количество ложных позитивных (неверно
классифицированных плохих примеров). Таким образом, даже если сильный
классификатор состоит из малого количества слабых классификаторов,
понижая порог, ценой большего числа ложных позитивных срабатываний можно свести
к минимуму количество ложных негативных.
.PP
Используя это свойство, из найденных слабых классификаторов можно составить
\*Iкаскад\*P, являющийся набором сильных классификаторов (называемых стадиями),
через которые последовательно проходит проверяемое изображение. Каждая стадия
содержит больше слабых классификаторов, чем предыдущие. После применения каждой
последующей стадии, вероятность ложного позитивного срабатывания снижается, а
вероятность ложного негативного остается маленькой.
.PP
Проверяемое изображение классифицируется положительно, только если оно дало
положительный результат на каждой стадии. Если изображение дало отрицательный
результат хотя бы на одной стадии, оно классифицируется отрицательно. Так как
на практике проверяется большое количество изображений, лишь малая часть
которых содержит искомый объект, большинство отсеивается на ранних стадиях
(тех, которые состоят из меньшего количества слабых классификаторов).
.sp 1.0v
.PSPIC cascade.eps 20m
.ps -2
.vs -2
.ce 100
Рис. 6. Иллюстрация структуры каскада.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
Рис. 6 иллюстрирует структуру каскада: круги \*- это слабые классификаторы
(цифры в кругах показывают их порядковый номер), каждый ряд кругов \*- это
стадия каскада.
.PP
Построить каскад классификаторов можно добавляя к текущей стадии слабые
классификаторы (и задавая нужный порог), пока доля ложных позитивных
срабатываний (отношение количества неверно классифицированных отрицательных
примеров к общему их количеству) на этой стадии больше заданного значения. Как
только доля ложных позитивных срабатываний стала меньше этого значения, надо
перейти к следующей стадии и точно также добавлять к ней слабые классификаторы.
Полный алгоритм будет выглядеть так:
.sp 0.5v
.RS
.PI
$N sub i$ \*- число слабых классификаторов на $i$-й стадии.
.PI
$theta sub i$ \*- порог на $i$-й стадии.
.PI
$n$ \*- номер текущей стадии.
.PI
$phi$ \*- заданное наперед значение.
.PI
$p sub i$ \*- доля ложных позитивных срабатываний $i$-й стадии.
.PI
$n sub i$ \*- доля ложных негативных срабатываний $i$-й стадии.
.PI
$a sub i$ \*- коэффициент $i$-го слабого классификатора.
.RE
.sp 1.0v
.RS
.PI 1.
Установить текущей стадией первую, сделав число слабых классификаторов на ней
равным 1:
.sp 1.0v
.EQ
n = 1
.EN
.sp 0.5v
.EQ
N sub n = 1
.EN
.sp 1.0v
.PI 2.
Установить для текущей стадии такой порог, чтобы все положительные примеры
классифицировались верно:
.sp 1.0v
.EQ
roman "установить" ~ {theta sub n}, roman "такой, что" ~ n sub n = 0
.EN
.sp 1.0v
.PI 3.
Если доля ложных позитивных срабатываний текущей стадии больше $phi$, увеличить
число слабых классификаторов на ней, в противном случае сделать текущей
следующую стадию, установив в ней число слабых классификаторов равным числу
слабых классификаторов предыдущей, увеличенному на $1$:
.sp 1.0v
.EQ
lpile {
roman "если" ~ {p sub n > phi}, roman "тогда" ~ N sub n = N sub n + 1
above
roman "иначе" ~ n = n + 1, N sub n = N sub {n - 1} + 1
}
.EN
.sp 1.0v
.PI 4.
Если число слабых классификаторов на текущей стадии меньше числа доступных
слабых классификаторов или доля ложных положительных срабатываний равна $0$,
перейти к пункту 2.
.PI 5.
Вернуть стандартный порог последней стадии, если выход из цикла произошел
из-за того, что закончились доступные слабые классификаторы:
.sp 1.0v
.EQ
roman "если" ~ {p sub n > 0}, roman "тогда" ~ theta sub n = 
size -2 {1 over 2} sum from {i = 1} to {N sub n} {a sub i}
.EN
.RE
.sp 0.5v
.PP
Стоит заметить, что не следует использовать для построения каскада те же
хорошие примеры, что и для нахождения слабых классификаторов. Так как слабые
классификаторы слишком хорошо обучены для этих примеров, требуемая доля ложных
позитивных срабатываний будет достигнута слишком быстро. В этом случае
полученный каскад будет содержать мало стадий и начнет допускать большое
количество ошибок.
.
.H2 "Оптимизация алгоритма построения" "каскада классификаторов"
.PP
Во втором пункте указанного выше алгоритма подразумевается, что требуемый порог
ищется перебором, что на практике не очень эффективно (как и в случае с
порогами слабых классификаторов, причиной этому являются большие затраты
времени и потери точности).
.PP
Однако, если использовать упрощенный вариант оптимизации, использовавшейся для
нахождения порогов слабых классификаторов, можно свести затраты времени на
построение каскада к минимуму.
.PP
Для того, чтобы применить этот метод, надо изменить условия, при которых порог
считается наилучшим. Также следует учесть, что у порога сильного классификатора
фиксированное направление знака неравенства ($>$).
.PP
Для слабого классификатора порог считался наилучшим, если сумма весов неверно
классифицированных примеров была минимальной. В сильных же классификаторах
наилучший порог тот, при котором верно классифицируются все хорошие примеры, а
также максимальное число отрицательных.
.PP
Значение, сравниваемое с порогом сильного классификатора, является суммой
коэффициентов тех классификаторов, которые верно классифицировали входное
изображение:
.sp 1.0
.EQ
sum from {i = 1} to N { {a sub i} {h dot} sub i}(E)
~ ,
.EN
.sp 1.0
где $N$ \*- число слабых классификаторов, $a sub i$ \*- коэффициент $i$-го
слабого классификатора, ${h dot} sub i$ \*- $i$-й слабый классификатор, а
$E$ \*- входное изображение.
.PP
Следовательно, чтобы все хорошие примеры были классифицированы верно,
достаточно, чтобы порог сильного классификатора был меньше такой суммы для
каждого из них. Или, если выражаться математически, порог должен быть
меньше наименьшей среди всех таких сумм для хороших примеров.
.PP
Учитывая, что чем порог ниже, тем больше плохих примеров будет
классифицировано неверно, условие стоит изменить так: порог должен быть меньше
наименьшей среди всех таких сумм для хороших примеров на наименьшее возможное
значение (в теории \*- бесконечно малое, а на практике \*- зависит от
реализации чисел с плавающей точкой на конкретной машине).
.PP
При таком условии, в отличие от порогов слабых классификаторов, не требуется
ни сортировки, ни проверки выбранного порога. Теперь можно оптимизировать
вычислениие сумм для хороших примеров. Для этого следует обратить внимание на
тот факт, что при каждой новой итерации число слабых классификаторов на текущей
стадии на $1$ больше, чем на предыдущей. Тогда вместо того, чтобы каждый раз
вычислять сумму заново, можно сделать дополнительный массив (для каждого
хорошего примера \*- соответствующий элемент массива) и при каждой итерации
добавлять туда необходимые слагаемые. Ниже приведен алгоритм с учетом всех
описанных оптимизаций:
.sp 0.5v
.RS
.PI
${h dot} sub i$ \*- $i$-й слабый классификатор.
.PI
$N sub i$ \*- число слабых классификаторов на $i$-й стадии.
.PI
$theta sub i$ \*- порог на $i$-й стадии.
.PI
$n$ \*- номер текущей стадии.
.PI
$phi$ \*- заданное наперед значение.
.PI
$p sub i$ \*- доля ложных позитивных срабатываний $i$-й стадии.
.PI
$n sub i$ \*- доля ложных негативных срабатываний $i$-й стадии.
.PI
$g sub i$ \*- $i$-й хороший пример.
.PI
$a sub i$ \*- коэффициент $i$-го слабого классификатора.
.PI
$s sub i$ \*- $i$-я ячейка дополнительного массива, соответствующая $i$-му
хорошему примеру.
.PI
$delta$ \*- миинимальное возможное число, которое можно вычесть из уменьшаемого.
.RE
.sp 1.0v
.RS
.PI 1.
Задать каждому элементу дополнительного массива значение $0$:
.sp 1.0v
.EQ
s sub i = 0
.EN
.sp 1.0v
.PI 2.
Установить текущей стадией первую, сделав число слабых классификаторов на ней
равным 1:
.sp 1.0v
.EQ
n = 1
.EN
.sp 0.5v
.EQ
N sub n = 1
.EN
.sp 1.0v
.PI 3.
Для всех хороших примеров: если последний классификатор текущей стадии
классифицировал пример верно, прибавить коэффициент этого классификатора к
значению в соответствующей примеру ячейке дополнительного массива:
.sp 1.0v
.EQ
{s sub i} = {h dot} sub {N sub n} ({g sub i})
.EN
.sp 1.0v
.PI 4.
Задать порогу текущей стадии такое значение, меньшее наименьшего элемента
дополнительного массива на минимально возможное число:
.sp 1.0v
.EQ
{s sub i} = min ({s sub i}) - delta
.EN
.sp 1.0v
.PI 5.
Если доля ложных позитивных срабатываний текущей стадии больше $phi$, увеличить
число слабых классификаторов на ней, в противном случае сделать текущей
следующую стадию, установив в ней число слабых классификаторов равным числу
слабых классификаторов предыдущей, увеличенному на $1$:
.sp 1.0v
.EQ
lpile {
roman "если" ~ {p sub n > phi}, roman "тогда" ~ N sub n = N sub n + 1
above
roman "иначе" ~ n = n + 1, N sub n = N sub {n - 1} + 1
}
.EN
.sp 1.0v
.PI 6.
Если число слабых классификаторов на текущей стадии меньше числа доступных
слабых классификаторов или доля ложных положительных срабатываний равна $0$,
перейти к пункту 2.
.PI 7.
Вернуть стандартный порог последней стадии, если выход из цикла произошел
из-за того, что закончились доступные слабые классификаторы:
.sp 1.0v
.EQ
roman "если" ~ {p sub n > 0}, roman "тогда" ~ theta sub n = 
size -2 {1 over 2} sum from {i = 1} to {N sub n} {a sub i}
.EN
.RE
.sp 0.5v
.H2 "Поиск объектов на большом изображении"
.PP
Обученный каскад Хаара может классифицировать только изображения того
же размера, что и обучающие примеры. Для того, чтобы искать объекты на большом
изображении, надо по отдельности классифицировать части этого изображения. Для
этого используется окно, двигаемое по изображению, размеры которого
соотвествуют рабочим размерам каскада. Если какая-либо часть изображения была
классифицирована положительно, значит в ней изображен искомый объект.
.PP
Также следует построить несколько маштабированных вариантов изображения (это
называется пирамидой изображений) и тоже пройтись по ним окном. Это необходимо
потому, что изображение искомого объекта совсем необязательно будет того же
размера, что и примеры из обучающей выборки. 
.PSPIC imagepyramid.eps 35m
.ps -2
.vs -2
.ce 100
Рис. 7. Пример пирамиды изображений: размер сторон каждой следующей версии
изображения равняется $0.75$ размера сторон предыдущего.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
В данной работе сначала с помощью окна проверяется исходное изображение. После
этого изображение уменьшается в заранее заданное количество раз и точно также
проверяется, пока длина одной из его сторон не станет меньше длины
соответствующей стороны окна. Если изображение в окне было классифицировано
положительно, кординаты углов этого окна переводятся в систему координат
исходного изображения и сохраняются в специальном массиве.
.
.H2 "Объединение пересекающихся прямоугольников"
.PP
Так как каскад Хаара имеет достаточно неплохую устойчивость к маштабированию
и смещению, после полного прохода по изображению и его маштабированным
вариантам искомый объект будет выделен окном несколько в соседних позициях и
маштабах.
.sp 1.0v
.PSPIC manywindows.eps 16m
.ps -2
.vs -2
.ce 100
Рис. 8. Пример выделения объекта после полного прохода окном по изображению:
зелеными прямоугольниками выделены области, изображение в которых было
классифицировано положительно.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
Чтобы исправить эту проблему, был выбран следующий подход: все прямоугольники
разбиваются на группы. Прямоугольник, принадлежащий какой-либо группе
пересекается хотябы с одним из других прямоугольников этой же группы. После
этого каждая группа заменяется одним прямоугольником, являющимся усереднением
всех прямоугольников этой группы.
.PP
Задачу объединения прямоугольников в группы можно хорошо описать и решить с
помощью понятий из теории графов. Прямоугольники можно считать вершинами графа.
Если они пересекаются, можно считать что они соединены ребром. Тогда если
разбить граф на компоненты связности, вершины принадлежащие одной и той же
компоненте и будут представлять из себя искомые группы.
.PP
Сначала надо представить набор прямоугольников в виде графа. Для этого
прямоугольники нумерются. Также каждому прямоугольнику в соотвествие ставится
список, содержащий номера других прямоугольников, пресекающих его. Полученные
списки и будут преставлять из себя граф. Построить эти списки можно по
следующему алгоритму:
.sp 0.5v
.RS
.PI
$r sub i$ \*- $i$ \*-й прямоугольник.
.PI
$R$ \*- количество имеющихся прямоугольников.
.PI
$e sub ij$ \*- номер (в $r sub i$) $j$-го прямоугольника из тех, которые
пересекаются с $i$-м прямоугольником.
.PI
$E sub i$ \*- количество прямоугольников, пресекающихся с $i$-м
прямоугольником. Изначально равно нулю.
.RE
.sp 1.0v
.RS
.PI
Для всех i и j от $0$ до $N$:
.RS
.PI
Если прямоугольники $r sub i$ и $r sub j$ пересекаются, добавить в список,
соответствующий вершине $r sub i$ значение  $j$:
.sp 0.5v
.EQ
roman "если" ~ r sub i , ~ r sub j ~ roman "пересекаются, тогда"
~ e sub {i {N sub i}} = j
.EN
.sp 0.5v
.EQ
N sub i = N sub i + 1
.EN
.RE
.RE
.sp 0.5v
.PP
Проверка пересечения двух прямоугольников выполняется с помощью проекций на
оси. То есть, проверяются на пересечение их проекций на ось $X$ и на ось $Y$ по
отдельности. Если пересечение имеется при проекций на обе оси, то
прямоугольники пересекаются. Проверка пересечений проекций выполняется
следующим образом:
.bp
.sp 0.5v
.RS
.PI
$A sub x0$, $A sub y0$ \*- наименьшие координаты угла первого прямоугольника.
.PI
$A sub x1$, $A sub y1$ \*- наибольшие координаты угла первого прямоугольника.
.PI
$B sub x0$, $B sub y0$ \*- наименьшие координаты угла второго прямоугольника.
.PI
$B sub x1$, $B sub y1$ \*- наибольшие координаты угла второго прямоугольника.
.RE
.sp 0.5v
.EQ
roman "если" ~ A sub x0 > B sub x1 ~ roman "или" ~ A sub x1 < B sub x0, ~
roman "то проекции на ось" ~ X ~ roman "пересекаются"
.EN
.sp 0.5v
.EQ
roman "если" ~ A sub y0 > B sub y1 ~ roman "или" ~ A sub y1 < B sub y0, ~
roman "то проекции на ось" ~ Y ~ roman "пересекаются"
.EN
.sp 0.5v
.PP
После этого требуется разбить полученный граф на компоненты связности. Если
точнее, требуется узнать, к какой компоненте относится каждая вершина.
Информация о ребрах внутри этих компонент, не требуется. Исходя из этого можно
использовать следующий алгоритм:
.sp 0.5v
.RS
.PI
$r sub i$ \*- соответствует $i$-й вершине. Если равен 1, то эта вершина была
достигнута из выбранной начальной вершины.
.PI
$R sub i$ \*- соответствует $i$-й вершине. Если равен 1, то эта вершина уже была
достигнута из другой вершины. Изначально равен $0$.
.PI
$V sub i$ \*- количество вершин, в $i$-й компоненте связности. Изначально равно
нулю.
.PI
$с sub ij$ \*- номер $j$-й вершины в $i$-й компоненте связности.
.PI
$C$ \*- количество компонент связности. Изначально равно нулю.
.PI
$e sub ij$ \*- номер $j$-й вершины из тех, в которые можно
попасть из $i$-й вершины.
.PI
$E sub i$ \*- количество вершин, в которые можно попасть из $i$-й вершины.
.PI
$n$ \*- номер вершины, с которой начинается выделение компоненты связности.
Изначально равен нулю.
.PI
$v$ \*- $i$-я вершина.
.PI
$N$ \*- общее количество вершин.
.RE
.sp 1.0v
.RS
Пока $n < N$:
.RS
.PI 1.
Обнулить $r sub i$:
.sp 0.5v
.EQ
roman "для всех" ~ i ~ roman "от" ~ 0 ~ roman "до" ~ N - 1 : r sub i = 0
.EN
.sp 0.5v
.PI 2.
Отметить все вершины, которые можно достигнуть из текущей вершины:
.sp 0.5v
.EQ
roman "если из вершины" ~ v sub n ~ roman "можно достигнуть вершину" ~ v sub i
, ~ roman "то" ~ r sub i = 1, ~ R sub i = 1
.EN
.sp 0.5v
.PI 3.
Добавить все отмеченные на текущем шаге вершины в новую компоненту связности:
.sp 0.5v
.EQ
roman "для всех" ~ i ~ roman "от" ~ 0 ~ roman "до" ~ N - 1 : ~ roman "если" ~
r sub i = 1 , ~ roman "тогда" ~ c sub {C {V sub C}} = i ,
~ V sub C = V sub C + 1
.EN
.sp 0.5v
.EQ
C = C + 1
.EN
.sp 0.5v
.PI 4.
Найти вершину с которой начнется выделение следующей компоненты связности:
.sp 0.5v
.EQ
roman "пока" ~ R sub n = 1 ~ roman "и" ~ n < N : ~ n = n + 1, 
.EN
.sp 0.5v
.RE
.RE
.sp 0.5v
.PP
Нахождение всех вершин, которые можно достигнуть из текущей выполняется простым
проходом по графу и отметкой уже пройденных вершин. В развернутом виде пункт 2.
будет выглядеть так:
.sp 1.0v
.RS
.PI 1.
Отметить вершину с номером $n$:
.sp 0.5v
.EQ
r sub n = 1
, ~
R sub n = 1
.EN
.sp 0.5v
.PI 2.
Перейти по всем ребрам вершины с номером $n$:
.sp 0.5v
.EQ
roman "для всех" ~ j ~ roman "от" ~ 0 ~ roman "до" ~ E sub i - 1 :
roman "если" ~ r sub {e sub ij} != 1,
roman "перейти к пункту 1. сделав" ~ n = e sub ij
.EN
.RE
.sp 1.0v
.PP
После того, как было определенно, к какой компоненте связности относится каждая
вершина, можно заменить каждую группу пересекающихся прямоугольников (каждой из
которых соответствует компонента связности графа) одним усередненным
прямоугольником.
.PP
В качестве усередненния используется прямоугольник, чьи наименьшие и
наибольшие координаты угла находятся как среднее арифметическое наименьших и
наибольших координат угла всех прямоугольников группы:
.RS
.sp 0.5v
.PI
$с sub ij$ \*- номер $j$-й вершины в $i$-й компоненте связности.
.PI
$C$ \*- количество компонент связности.
.RE
.sp 1.0v
.
.
.H1 "Исправление искажений перспективы"
.PP
После того, как область, в которой находится пластина с автомобильным номером,
была выделена, ее следует привести к виду, пригодному для распознаванию
отдельных символов на этой пластине. Одна из основных проблем, мешающих
корректному распознаванию символом \*- это искажения перспективы, возникающие
когда номер снимается не под прямым углом.
.PP
Для решения этой проблемы используется комбинация нескольких методов. Сначала
вычисляется градиент изображения, на котором лучше видны резкие перепады
яркости. С его помощью на этом изображении обнаружаются контуры объектов. Среди
найденных контуров выделяются только те, которые являются прямыми линиями.
Далее из них выбирается четыре линии, с наибольшей вероятностью являющиеся
контурами пластины с номером. После этого, с помощью этих четырех линий,
находятся углы пластины с номером и вычисляется, каким образом нужно
преобразовать изображение, что бы исправить искажения перспективы.
.sp 1.0v
.PSPIC perspin.eps 12m
.ps -2
.vs -2
.ce 100
Рис. 9. Пример пластины с номером, обнаруженной на фотографии. Зелеными точками
обозначены углы номерной пластины.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PSPIC perspout.eps 12m
.ps -2
.vs -2
.ce 100
Рис. 10. Пластина с номером после исправления искажений перспективы. В таком
виде номер пригоден для дальнейшего распознавания.
.ce 0
.ps +2
.vs +2
.
.H2 "Градиент изображения. Оператор Собеля"
.PP
Градиент изображения \*- это набор векторов, в котором каждый элемент (вектор)
соответствует своему пикселю изображения. Направление вектора указывает из
соответствующего ему пикселя в ту сторону, двигаясь в которую, значения
пикселей будут возрастать быстрее всего, а модуль его показывает скорость
возрастания этих значених.
.PP
Если рассматривать непрерывную функцию, ее градиент является суммой
произведений производных по $x$, $y$ и векторов $i = (1,0)$, j = $(0,1)$ (такие
вектора называются базисными), соответственно:
.sp 0.5v
.EQ
{grad sub f} = {delta f} over {delta x} i+ {delta f} over {delta y} j
~ ,
.EN
.sp 0.5v
где $f$ \*- непрерывная функция, для которой ищется градиент, а $grad sub f$
\*- искомый градиент функции $f$.
.PP
Так как изображение, по сути, является дискретной функцией, т.е. функцией,
изменяющейся скачками, вычисление вектора градиента в каждой точке требует
прохода по всему изображению. Поэтому, градиент изоображения обычно вычисляется
приближенно. Для этого используется \*IОператор Собеля\*P, представляющий из
себя две матрицы $3 times 3$, использующихся для нахождения приближенных
производных по $x$ и по $y$ по отдельности.
.PP
Данные матрицы выглядят следующим образом:
.sp 0.5v
.EQ
{S sub x} =
left [
matrix {
ccol {-1 above  0 above 1}
ccol {-2 above 0 above 2}
ccol {-1 above  0 above 1}
}
right ]
~, ~~~
{S sub y} =
left [
matrix {
ccol {-1 above  -2 above -1}
ccol {0 above 0 above 0}
ccol {1 above  2 above 1}
}
right ]
~ .
.EN
.sp 0.5v
.PP
Для приближенного вычисления проризводных используется операция свертки:
.sp 0.5v
.EQ
{G sub x} = S sub x * I = sum from {i = 1} to 3
sum from {j = 1} to 3 I [x - i, y - j] ~ S sub x [i, j]
.EN
.sp 0.5v
.EQ
{G sub y} = S sub y * I = sum from {i = 1} to 3
sum from {j = 1} to 3 I [x - i, y - j] ~ S sub y [i, j]
~, 
.EN
.sp 0.5v
где $I[x, y]$ \*- пиксель с координатами [x, y], а $S sub y [i, j]$ и
$S sub x [i, j]$ \*- элемент матрицы $S sub x$ или $S sub y$, соответственно,
находящийся в $i$-й столбце и $j$-й колонке. После этого, с помощью найденных
производных по $x$ и $y$ находятся направление и модуль градиента:
.sp 0.5v
.EQ
G = sqrt {{G sub x} sup 2 + {G sub y} sup 2}
.EN
.sp 0.5v
.EQ
theta = roman "arctan" size -2 {{G sub y} over {G sub x}}
~ ,
.EN
.sp 0.5v
где $G$ \*- модуль градиента в точке, $theta$ \*- направление градиента в
точке\[one], а $G sub x$ и $G sub y$ \*- значения частных производных по $x$ и
$y$ в этой точке.
.
.FS \[one]
Важно учитывать, что если и $G sub x$, и $G sub y$ в точке отрицательны, то
минусы "уничтожают" друг друга. Этот случай следует обрабатывать отдельно, так
как иначе будет полученое неверное значение.
.FE
.
.
.H2 "Детектор границ Канни"
.PP
Обнаружениие границ выполняется с помощью \*Iдетектора границ Канни\*P.
Детектор границ Канни является алгоритмом \*Iбинаризации\*P, т.е. он разделяет
пиксели на две группы: в первой группе находятся пиксели контура, а во второй
\*- все остальные.
.PP
Данный алгоритм использует вычисленный с помощью оператора Собеля (или любым
другим способом) градиент и состоит из нескольких этапов. Сначала выполняется
\*Iподавлениие немаксимумов\*P среди значений модуля градиента, потом
выполняется \*Iдвойная пороговая фильтрация\*P. После этого обрабатываются
пиксели, принадлежность контуру которых не была опредена на предыдущем этапе.
.PP
Результат возвращается в виде изображения (маски), где каждый пиксель
соответствует пикселю исходного изображения с такими же координатами. Пиксели
маски принимают одно из двух значений: 0 \*- если соответствующая точка
исходного изображения не принадлежит границе, и любого другое значение, если
принадлежит.
.PP
Подавление немаксимумов требуется для того, чтобы выделенная граница была
мининальной толщины, иначе говоря, чтобы она была четкой настолько, наколько
это возможно. Для этого выполняется проход по всем точкам градиента, и, если
значение градиента в точке меньше, чем значение градиента в двух соседних
точках (находящихся слева и справа от вектора направления градиента), то ему
присваивается значение $0$.
.PP
Для упрощения реализации угол направления градиента дискретизируется,
т.е., вместо вещественных чисел представляется фиксированным количеством
значений. На основе дискретизированного значения угла уже определяется, с
какими соседними значениями градиента сравнивать значение градиента в текущей
точке. Ниже приведен полный алгоритм подавления немаксимумов:
.sp 0.5v
.RS
.PI
$G ^ [x, y]$ \*- значение градиента в точке с координатами [x, y].
.PI
$theta ^ [x, y]$ \*- угол градиента с осью $X$ в точке с координатами [x, y].
.PI
$w$ \*- ширина исходного изображения.
.PI
$h$ \*- высота исходного изображения.
.PI
$T$ \*- дискретизированное значение угла.
.PI
$L sub x$ \*- координата $x$ точки слева от вектора направления градиента.
.PI
$L sub y$ \*- координата $y$ точки слева от вектора направления градиента.
.PI
$R sub x$ \*- координата $x$ точки справа от вектора направления градиента.
.PI
$R sub y$ \*- координата $y$ точки справа от вектора направления градиента.
.RE
.sp 1.0v
.RS
Для всех $x$ от $1$ до $w$:
.RS
Для всех $y$ от $1$ до $h$:
.RS
.PI 1.
Дискретизировать\[one] угол направления градиента в точке $[x, y]$:
.
.FS \[one]
Здесь предполагается, что $theta ~ [ x, y ]$ лежит в интервале
$[ 0 ^ ; 2 pi ]$. Если это не так, пред этим его следует привести к этому
интервалу.
.FE
.
.sp 0.5v
.EQ
lpile {
T =  size -2 {{8 ^ left ( theta ^ [x, y] + size -2 {pi over 8} right )} over
{2 pi}} ~ roman "mod" ~ 8
= left [ size -2 {{4 theta ^ [x, y]} over pi} + size -2 {1 over 2} right ]
~ roman "mod" ~ 8
}
.EN
.sp 0.5v
.PI 2.
Определить, с какими из соседних точек следует сравнивать значение градиента:
.sp 0.5v
.EQ
lpile {
roman "если" ~ T = 0 ~ roman "или" ~ T = 4 ^ : ~ roman "тогда" ~
L sub x = x, ~~ L sub y = y + 1, ~~ R sub x = x, ~~ R sub y = y - 1
above
roman "если" ~ T = 2 ~ roman "или" ~ T = 6 ^ : ~ roman "тогда" ~
L sub x = x - 1, ~~ L sub y = y, ~~ R sub x = x + 1, ~~ R sub y = y
above
roman "если" ~ T = 1 ~ roman "или" ~ T = 5 ^ : ~ roman "тогда" ~
L sub x = x - 1, ~~ L sub y = y - 1, ~~ R sub x = x + 1, ~~ R sub y = y + 1
above
roman "если" ~ T = 3 ~ roman "или" ~ T = 7 ^ : ~ roman "тогда" ~
L sub x = x - 1, ~~ L sub y = y + 1, ~~ R sub x = x + 1, ~~ R sub y = y - 1
}
.EN
.sp 0.5v
.PI 3.
Сравнить значение градиента со значениями градиента в выбранных соседних
точках. Если оно меньше любого из них, заменить его значение нулем:
.sp 0.5v
.EQ
roman "если" ~ G ^ [ x, y ] < G ^ [ L sub x, L sub y ]
~ roman "или" ~ G ^ [ x, y ] < G ^ [ R sub x, R sub y ]
^ : ~ roman "тогда" ~ G ^ [x, y] ~ roman "mod" ~ = 0
.EN
.sp 0.5v
.RE
.RE
.RE
.sp 0.5v
.PP
После подавления немаксимумов выполняется двойная пороговая фильтрация.
Выбирается два значения (порога). Они задаются либо вручную, либо определяются
динамически (например, \*Iметодом Оцу\*P). Точки, в которых значение градиента
больше наибольшего из двух порогов, отмечаются как точки границы. Те точки,
значения которых лежат между двумя порогами, отмечаются как неопределенные.
Остальные точки отмечаются как фоновые (не являются точками границы):
.sp 0.5v
.RS
.PI
$G ^ [x, y]$ \*- значение градиента в точке с координатами [x, y].
.PI
$theta sub 1$ \*- наименьший из двух порогов
.PI
$theta sub 2$ \*- наибольший из двух порогов
.PI
$w$ \*- ширина исходного изображения.
.PI
$h$ \*- высота исходного изображения.
.PI
$m ^ [x, y]$ \*- точка $[x, y]$ выходной маски. Если ее значение равно $0$, то
точка $[x, y]$ изображения \*- фоновая, если $2$ \*- то это точка контура, если 
$1$ \*- ее принадлежность контуру пока не определена.
.RE
.sp 1.0v
.RS
Для всех $x$ от $1$ до $w$:
.RS
Для всех $y$ от $1$ до $h$:
.RS
.PI
Сравнить значение градиента в точке $[x, y]$ с порогами $theta sub 1$ и
$theta sub 2$:
.sp 0.5v
.EQ
lpile {
roman "если" ~ G ^ [x, y] < {theta sub 1} : ~ roman "тогда" ~ m ^ [ x, y ] = 0
above
roman "если" ~ G ^ [x, y] > {theta sub 2} : ~ roman "тогда" ~ m ^ [ x, y ] = 2
above
roman "если" ~ G ^ [x, y] > {theta sub 1} ~ roman "и"
~ G ^ [x, y] < {theta sub 2} : ~ roman "тогда" ~ m ^ [ x, y ] = 1
}
.EN
.sp 0.5v
.RE
.RE
.RE
.sp 0.5v
.PP
Далее обрабатываются точки, отмеченые как неопределенные. Это делается
следующим образом: если принадлежность точки контуру не была определена на
предыдущем этапе, но при этом хотябы одна из $8$ соседних для нее точек
принадлежит контуру, то она тоже помечается как точка контура:
.RS
.PI
$G ^ [x, y]$ \*- значение градиента в точке с координатами [x, y].
.PI
$w$ \*- ширина исходного изображения.
.PI
$h$ \*- высота исходного изображения.
.PI
$m ^ [x, y]$ \*- точка $[x, y]$ выходной маски. Если ее значение равно $0$, то
точка $[x, y]$ изображения \*- фоновая, если $2$ \*- то это точка контура, если 
$1$ \*- ее принадлежность контуру пока не определена.
.RE
.sp 1.0v
.RS
Для всех $x$ от $1$ до $w$:
.RS
Для всех $y$ от $1$ до $h$:
.RS
.PI
Сравнить значение градиента в точке $[x, y]$ с порогами $theta sub 1$ и
$theta sub 2$:
.sp 0.5v
.EQ
lpile {
roman "если" ~ m ^ [x, y] = 1 :
above
~~~~ roman "если" ~ m ^ [x - 1, y - 1] = 2
~ roman "или если" ~ m ^ [x - 1, y] = 2
~ roman "или если" ~ m ^ [x - 1, y + 1] = 2
above
~~~~ roman "или если" ~ m ^ [x, y - 1] = 2
~ roman "или если" ~ m ^ [x, y] = 2
~ roman "или если" ~ m ^ [x, y + 1] = 2
above
~~~~ roman "или если" ~ m ^ [x + 1, y - 1] = 2
~ roman "или если" ~ m ^ [x + 1, y] = 2
above
~~~~ roman "или если" ~ m ^ [x + 1, y + 1] = 2 :
above
~~~~~~~~ roman "тогда" ~ m [x , y] = 2 ^ ,
above
~~~~ roman "иначе" ~ m ^ [x + 1, y + 1] = 0
}
.EN
.sp 0.5v
.RE
.RE
.RE
.
.PSPIC cannyin.eps 12m
.PSPIC cannyout.eps 12m
.ps -2
.vs -2
.ce 100
Рис. 11. Пример работы детектора границ Канни: сверху находится исходное
изображение, а снизу выходное изображение детектора.
.ce 0
.ps +2
.vs +2
.
.H2 "Преобразование Хафа"
.PP
После того, как контуры были выделены детектором границ Канни, среди них ищутся
прямые линии. Для этого используется преобразование Хафа. Оно, как и детектор
границ Канни, состоит из нескольких этапов. Сначала выполняется поиск прямых.
Далее выполняется подавление немаксимумов. А после этого линии, оставшиеся
после предыщего этапа сортируются по количеству голосов, полученных на первом
этапе.
.PP
Для поиска прямых в используется \*Iаккумулирующий массив\*P. Каждый элемент
массива соотвествуют одной из всех возможных прямых. Он является целым числом,
позывающим сколько точек, принадлежащих границе, лежит на этой прямой.
.PP
Изначально всем элементам аккумулирующего массива присваивается значение $0$,
далее выполняется проход по всем точкам, принадлежащим контуру. Для каждой
такой точки определяются все прямые, которые могут через нее проходить и
значения элементов аккумулирующего массива, соответствующие этим прямым,
увеличиваются на $1$.
.PP
Для поиска всех прямых, на которых может лежать точка (а также для определения
количества элементов аккумулирующего массива) используется уравнение прямой,
записанное в специальной форме:
.sp 0.5v
.EQ
r = x cos theta + y sin theta
~ ,
.EN
.sp 0.5v
где $theta$ \*- угол нормали прямой с осью $X$, а $r$ \*- минимальное
расстояние от точки $[0, 0]$ до прямой.
.sp 0.5v
.
.PSPIC houghline.eps 15m
.ps -2
.vs -2
.ce 100
Рис. 12. Представление прямой через угол нормали с осью $X$ и длину
перпендиикуляра.
.ce 0
.ps +2
.vs +2
.sp 0.5v
.PP
Так как параметры $theta$ и $r$ \*- вещественные числа, возможных прямых
бесконечное множество. Следовательно, полный их перебор невозможен. Поэтому
$theta$ и $r$ дискретизируются с заранее заданным шагом. Т.е. расстояние между
двумя соседними значениями параметра в дискретизированным виде равно
фиксированному значению (шагу). В данной работе параметр $theta$
дискретизируется с шагом  $size -2 {pi over 180}$ (вместо радиан используются
целые углы), а параметр $r$ с шагом $1$ (просто округляется до ближайщего
целого).
.PP
Все прямые, проходящие через точку находятся с помощью приведенного выше
уравнения прямой. Выполняется проход для всех возможных значений $theta$, на
каждом шаге текущее значения $theta$ и координат точки подставляются в
уравнение прямой, и вычисляется значение параметра $r$. Так как при
фиксированном значении параметра $theta$, через конкретную точку может
проходить только одна прямая, таким образом можно найти все искомые прямые.
.PP
Для того чтобы быстро определять, какой элемент аккумулирующего массива
соответствует найденной прямой, аккумулирующий массив следует представить в
виде изображения. Для этого надо расположить его элементы в несколько строк
так, чтобы все элементы одной строки соответствовали прямым с одинаковым
значением $r$ (равным \*Iномеру\*P строки) и разными значениями
$theta$ (равными \*Iномеру\*P элемента в строке). Такое представление иногда
называют пространством Хафа. Теперь, для того, чтобы определить, какой элемент
аккумулирующего массива соответствует прямой со значениями параметров $theta$ и
$r$, достаточно найти точку в пространстве Хафа с координатами $[ theta , r ]$.
.PP
Важно отметить, что при представлении изображения в компьютере значения
координат точки (пикселя) обычно являются положительными целыми числами, а
значения параметров прямой не обязательно являются целыми и могут быть
отрицательными. Эта проблема решается в помощью смещения и маштабирования, т.е.
прямой со значениями параметров $theta$ и $r$ соотвествует элемент
аккумуллирующего массива с координатами
$[ a sub theta theta + b sub theta , a sub r r + b sub r ]$, где 
$a sub theta$ и $a sub r$ \*- маштабирующие коэффициенты параметров прямой,
а $b sub theta$ и $b sub r$ \*- их смещения.
.PP
Ниже приведен полный алгоритм нахождения прямых:
.sp 0.5v
.RS
.PI
$A ^ [a, d]$ \*- элемент аккумулирующего массива с координатами $[ a , d ]$.
.PI
$w$ \*- ширина входного изображения.
.PI
$h$ \*- высота входного изображения.
.PI
$T$ \*- ширина аккумулирующего массива.
.PI
$R$ \*- высота аккумулирующего массива.
.PI
$d theta$ \*- шаг дискретизации параметра $theta$.
.PI
$d r$ \*- шаг дискретизации параметра $r$.
.PI
$theta$ \*- значение параметра $theta$ текущей прямой.
.PI
$r$ \*- значение параметра $r$ текущей прямой.
.RE
.sp 1.0v
.RS
Для всех $x$ от $1$ до $w$:
.RS
Для всех $y$ от $1$ до $h$:
.RS
Если значение пикселя входного изображения с координатами $[ x , y ]$ не равно
$0$:
.RS
Для всех $a$ от нуля до T:
.RS
.PI 1.
Вычислить значение $theta$ для текущей прямой:
.sp 0.5v
.EQ
theta = a cdot d theta
.EN
.sp 0.5v
.PI 2.
Вычислить значение $r$ для текущей прямой:
.sp 0.5v
.EQ
r = x cos theta + y sin theta
.EN
.sp 0.5v
.PI 3.
Увеличить значение элемента аккумулирующего массива, соответствующего текущей
прямой:
.sp 0.5v
.EQ
A ^ [a, d + size -2 {R over 2}] = A ^ [a, d + size -2 {R over 2}] + 1
.EN
.sp 0.5v
.RE
.RE
.RE
.RE
.RE
.sp 0.5v
.PP
После заполнения аккумулирующего массива из него следует выбрать элементы,
являющееся максимумами и посторить из них список. При этом используется метод,
очень похожий на подавление немаксимумов в детекторе границ Канни. Только
сравнениие выполняется с четырьмя соседними элементами вместо двух:
.sp 0.5v
.RS
.PI
$A ^ [a, d]$ \*- элемент аккумулирующего массива с координатами $[ a , d ]$.
.PI
$T$ \*- ширина аккумулирующего массива.
.PI
$R$ \*- высота аккумулирующего массива.
.PI
${l sub theta} ^ [i]$ \*- параметр $theta$ $i$-й прямой в заполняемом списке.
.PI
${l sub r} ^ [i]$ \*- параметр $r$ $i$-й прямой в заполняемом списке.
.PI
${l sub v} ^ [i]$ \*- количество голосов, отданных за $i$-ю прямую в
заполняемом списке.
.PI
$L$ \*- количество прямых в заполняемом списке. Изначально равно нулю.
.PI
$d theta$ \*- шаг дискретизации параметра $theta$.
.PI
$d r$ \*- шаг дискретизации параметра $r$.
.RE
.sp 1.0v
.RS
Для всех $a$ от $1$ до $T$:
.RS
Для всех $d$ от $1$ до $R$:
.RS
Если значение элемента аккумулирующего массива с координатами $[a, d]$ не равно
нулю:
.RS
.PI
Если значение элемента аккумулирующего массива с координатами $[a, d]$
больше всех четырех соседних элементов, добавить значение параметров $theta$ и
$r$ прямой, которой он соответствует, в список:
.sp 0.5v
.EQ
lpile {
roman "если" ~ A ^ [a, d] > A ^ [a, d - 1] 
~ roman "и" ~ A ^ [a, d] > A ^ [a, d + 1]
above
~~~~ roman "и" ~ A ^ [a, d] > A ^ [a - 1, d]
~ roman "и" ~ A ^ [a, d] > A ^ [a + 1, d] ^ :
above
~~~~~~~~ roman "тогда" ~ l sub theta ^ [L] = a cdot d theta ,
~ l sub r ^ [L] = d - size -2 {R over 2}, ~ l sub v ^ [L] = A ^ [a, d] ,
~ L = L + 1
}
.EN
.RE
.RE
.RE
.RE
.sp 0.5v
.PP
После этого прямые в полученном списке сортируются по количеству голосов (по
убыванию) любым способом, например, \*Iбыстрой сортировкой\*P. На выход
подается отсортированный список, содержащий значения параметров $theta$ и $r$
найденых прямых.
.
.H2 "Поиск границ пластины" "с автомобильным номером"
.PP
Данный раздел раздел посвящен тому, каким образом комбинируются описанные
выше методы для того, чтобы находить границы номера.
.PP
Основой поиска границ пластины с номером в данной работе является выбор самых
ярких прямых (получивших больше всего голосов), найденных преобразованием Хафа.
Однако, границы пластины с номером не всегда являются самыми яркими прямыми. 
.PP
Так как заранее примерно известно, в какой части изображения можно найти каждую
из четырех границ, то первое, что можно сделать, чтобы это исправить \*- это
разбить изображение на части и в каждой части искать отдельную границу.
.PP
Для поиска горизонтальных границ изображение разбивается горизонтальным
сечением на две части: верхнюю и нижнюю половины. В верхней половине ищется
верхняя граница номера, а в нижней \*- нижняя. Для поиска вертикальных границ
изображение разбивается вертикальным сечением на несколько равных частей (в
данной работе \*- на пять). В самой левой части ищется левая граница номера,
а в самой прямой \*- правая.
.sp 1.0v
.PSPIC num.eps 12m
.ps -2
.vs -2
.ce 100
Рис. 13. Исходное изображение пластины с номером.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PSPIC numhorseg.eps 12m
.ps -2
.vs -2
.ce 100
Рис. 14. Изображение пластины с номером, разбитое на верхнюю и нижнюю половины.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PSPIC numverseg.eps 12m
.ps -2
.vs -2
.ce 100
Рис. 15. Изображение пластины с номером, разбитое на пять частей вертикальным
сечением.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
Для того, чтобы вертикальные границы пластины с номером (так как они менее
яркие, чем горизонтальные) лучше обнаруживались c помощью преобразования Хафа,
части изображения, в которых они ищутся, растягиваются по высоте (в данной
работе они растягиваются так, чтобы их высота была равна ширине всего
изображения с пластиной). Таким образом все вертикальные прямые на них при
преобразовании Хафа получат больше голосов.
.sp 1.0v
.PSPIC numversegstretched.eps 5m
.ps -2
.vs -2
.ce 100
Рис. 16. Растянутые изображения, в которых ищутся вертикальные границы.
.ce 0
.ps +2
.vs +2
.sp 1.0v
.PP
Также, можно использовать разные дополнительные условия, чтобы отсеять
некоторые яркие прямые (найденные с помощью преобразования Хафа), не являющиеся
границами пластины с номером. В данной работе использется два дополнительных
условия.
.PP
Первое из них заключается в проверке угла наклона прямых. Если ищется верхняя
или нижняя граница номера, то прямые, параметр $theta$ которых меньше
$size -2 {pi over 4}$ или больше $size -2 {{3 pi} over 4}$ (т.е. прямые, не
являющиеся горизонтальными) не рассматриваются. Аналогично, если ищется левая
или правая граница: не рассматриваются прямые, чей параметр $theta$ больше
$size -2 {pi over 4}$ и меньше $size -2 {{3 pi} over 4}$ (прямые, не являющиеся
вертикальными).
.PP
Второе дополнительное условие основанно на том факте, пластина с автомобильным
номером обычно белого цвета и имеет черные края. Поэтому второе условие
заключается в сравненнии сумм яркостей в двух полосах (область изображения,
ограниченная двумя прямыми). Первая полоса, лежит непосредственно на
обнаруженной прямой. Вторая полоса лежит вплотную к первой по ту сторому от
нее, по которую должна находиться пластина с номером. Если сумма яркостей
пикселей, находящихся в первой полосе меньше, чем такая же сумма во второй
полосе, то обнаруженная прямая считается границей пластины с номером, иначе
прямая больше не рассматривается.
.PP
Второе условие применяется только при поиске вертикальных границ пластины с
номером (горизонтальные прямые, для которых выполняется первое условие, сразу
считаются границами пластины с номером), так как на практике результат этой
проверки для горизонтальных границ был неудовлетворительным. Это следствие
того, что горизонтальные границы пластины итак обычно являются самыми яркими,
и, следовательно добавление этой проверки при их поиске несет лишь
дополнительные ошибки распознавания.
.PP
Ширина полосы выбирается как доля от ширины или высоты. Т.е. ширина
горизонтальных полос равняется высоте изображения, умноженной на заранее
определенную константу (которая больше нуля и меньше единицы), а ширина
вертикальных полос \*- равняется ширине изображения, умноженной на другую
заранее определенную константу (которая также больше нуля и меньше единицы).
.PP
Каждая полоса представляется в виде двух прямых (границ полосы), чьи параметры
$theta$ равны, а параметры $r$ отличаются на ширину полосы (т.е. модуль их
разности равен ширине полосы). Для того, чтобы проверить, лежит ли точка в
полосе, ищется прямая, проходящая через эту точку, с таким же параметром
$theta$, как и границы полосы. Если значение параметра $r$ этой прямой лежит
между значениями параметров $r$ границ полосы, то точка лежит в полосе.
.PP
Нахождение параметра $r$ такой прямой, по сути, является нахождением проекции
точки $[x, y]$ на перпендикуляр к границам полосы. Эту проекцию можно найти как
длину катета, прилежащего к углу между прямой, проведенной из точки $[0, 0]$ в
точку $[x, y]$ и перпендикуляром к границам полосы.
.PP
Алгоритм суммирования яркостей всех пикселей, лежащих в полосе выглядит так:
.sp 1.0v
.RS
.PI
$I ^ [x, y]$ \*- пиксель изображения (содержащего яркости), на котором ищется
прямая.
.PI
$w$ \*- ширина изображения, на котором ищется прямая.
.PI
$h$ \*- высота изображения, на котором ищется прямая.
.PI
$theta$ \*- параметр $theta$ обоих прямых, составляющих полосу.
.PI
$r sub 0$, $r sub 1$ \*- параметр $r$ первой и второй прямых составляющих
полосу. $r sub 0$ должен быть меньше, чем $r sub 1$.
.PI
$phi$ \*- угол прямой, проведенной из точки $[0, 0]$ в точку $[x, y]$ с осью
$X$.
.PI
$d$ \*- длина прямой, проведенной из точки $[0, 0]$ в точку $[x, y]$. 
.PI
$rho$ \*- проекция точки $[x, y]$ на перпендикуляр к границам полосы.
.PI
$S$ \*- сумма пикселей в полосе. Изначально равна нулю.
.RE
.sp 1.0v
.RS
Для всех $a$ от $1$ до $w$:
.RS
Для всех $d$ от $1$ до $h$:
.RS
.PI 1.
Вычислить длину и угол с осью $X$ прямой, проходящей из точки $[0, 0]$ в точку
$[x, y]$:
.sp 0.5v
.EQ
phi = roman "arctan" size -2 {y over x}
.EN
.sp 0.5v
.EQ
d = sqrt{x sup 2 + y sup 2}
.EN
.sp 0.5v
.PI 2.
Вычислить значение проекции точки $[x, y]$ на перпендикуляр к границам полосы:
.sp 0.5v
.EQ
rho = d cos ({phi - theta})
.EN
.sp 0.5v
.PI 3.
Если проекция точки $[x, y]$ лежит между параметрами $r$ границ полосы, то
она лежит в полосе и, следовательно, значение яркости пикселя с этими
координатами надо прибавить к сумме:
.sp 0.5v
.EQ
roman "если" ~ rho > r sub 0 ~ roman "и" ~ rho < r sub 1 :
~ roman "тогда" ~ s = s + I ^ [x, y]
.EN
.sp 0.5v
.RE
.RE
.RE
.PP
После того, как граница пластины с номером была найдена, она переводится из
представления через перпендикуляр и его угол с осью $X$ в представление через
две точки, лежащие на ней:
.sp 0.5v
.EQ
lpile {
roman "если" ~ theta > epsilon ~ : ~ 
above
roman "иначе" ~
}
lpile {
p sub 0x = 0, ~~ p sub 0y = size -2 {r over {sin theta}}, ~~
p sub 1x = w, ~~ p sub 1y = r - w size -2 {{cos theta} over {sin theta}} ,
above
p sub 0x = r , ~~ p sub 0y = 0, ~~
p sub 1x = r , ~~ p sub 1y = h
}
~ ,
.EN
.sp 0.5v
где $theta$ и $r$ \*- параметры прямой в представлении через перпендикуляр и
его угол с осью $X$, $w$ и $h$ \*- ширина и высота изображения с пластиной,
$p sub 0x$ и $p sub 0y$ \*- координаты первой точки в новом представлении
линии, а $p sub 1x$ и $p sub 1y$ \*- координаты второй точки в новом
представлении линии.
.PP
После того, как были найдены все четыре границы пластины, составляющие контур
номера, ищутся координаты её углов. Для этого находятся точки пересечения левой
и верхней (левый верхний угол пластины), левой и нижней (левый нижний угол
пластины), правой и верхней (правый верхний угол пластины), правой и нижней
(правый нижний угол пластины) границ.
.PP
Далее, c помощью найденных координат углов выполняется перспективное
преобразование изображения с пластиной, и после этого выполняется распознавание
отдельных символов на пластине.
.
.
.H1 "Заключение"
.PP
В результате проделанной работы был написан набор утилит для Unix-подобных
систем, предназначенных для распознавания номеров. Их список включает в себя:
утилиту для поиска слабых классификаторов каскада Хаара, утилиту для построения
каскада Хаара из найденных примитивов, утилиту для поиска объектов на
изображении с помощью обученного каскада Хаара (имеется уже обученный под поиск
пластины с номером каскад), а также утилиту для исправления перспективных
искажений в найденном изображении с пластиной.
.PP
Был исследован и описан ряд методов, применяемых при обработке изображений, а
также была предпринята попытка объяснить их суть доступным языком. Эти методы
могут быть полезны в других задачах, связанных с обработкой изображений.
.PP
Данная работа имеет ряд недостатков. Каскад Хаара не может обнаружать
объекты, сильно наклоненные относительно того объекта, под который он обучался.
Поэтому, автомобильные номера, сфотографированные под нестандартными углами,
обычно не обнаружаются. Это не является серьезным недостатком, так как
написанные утилиты в основном предназначены для специальных камер, снимающих
машины под требуемым углом. Также, эту проблему можно решить, проверяя
помимо исходного изображения его копии, повернутые на фиксированный угол. 
.PP
Детектор границ Канни периодически может давать сбой. Это обычно связано с
плохим освешением, грязными номерами, большим уровнем шума, яркими границами у
пластины с номером или её физизескими искажениями (например, если пластина с
номером загнута). В итоге, для дальнейшего распознавания пригодно только около
$80%$ обнаруженных номеров.
.PP
Дальнешую работу планируется направить на исправление описанных выше
недостатков. После этого планируется искать способы распознавания отдельных
символов на изображении, полученном после исправления перспективных искажений.
.
.H1 "Список литературы"
.RS
.PI 1.
\*IAn Introduction to Practical Neural Networks and Genetic Algorithms For
Engineers and Scientists. Christopher MacLeod.\*P \*- небольшая книга,
посвященная нейронным сетям и генетическим алгоритмам. Также, в ней описаны
разные методы, применяемые при машинном обучении.
.PI 2.
\*IRapid Object Detection using a Boosted Cascade of Simple Features.
Paul Viola, Michael Jones.\*P \*- оригинальная статья, в которой были
представлены каскады Хаара, содержит часть информации, необходимой для их
реализации.
.PI 3.
\*IDigital Image Processing. Rafael C. Gonzalez, Richard E. Woods.\*P \*-
книга, посвященная цифровой обработке изображений. В ней описывается большая
часть методов, применяемых в этой работе при исправлении искажений перспективы.
.PI 4.
\*IБез паники! Цифровая обработка сигналов. Юкио Сато.\*P \*- введение в
цифровую обработку сигналов.
.PI 5.
\*IThe Scientist and Engineer's Guide to Digital Signal Processing.
Steven W. Smith.\*P \*- книга, посвященная цифровой обработке сигналов. В ней
описано множетсво методов, применяемых улучшении сигналов и их анализе.
.RE
